from torch.utils.tensorboard import SummaryWriter
import os
import json
from fusion_model import GatedFusion
from utils import Log
from torch.utils.data import DataLoader
from ent_init_model import EntInit
from rgcn_model import RGCN
from multi_view_rgcn import MultiViewRGCN
from kge_model import KGEModel
import torch
import torch.nn.functional as F
from collections import defaultdict as ddict
from utils import get_indtest_test_dataset_and_train_g
from datasets import KGEEvalDataset


class Trainer(object):
    def __init__(self, args):
        self.args = args

        # writer and logger
        self.name = args.name
        self.writer = SummaryWriter(os.path.join(args.tb_log_dir, self.name))
        self.logger = Log(args.log_dir, self.name).get_logger()



        # state dir
        self.state_path = os.path.join(args.state_dir, self.name)
        if not os.path.exists(self.state_path):
            os.makedirs(self.state_path)

        indtest_test_dataset, indtest_train_g = get_indtest_test_dataset_and_train_g(args)
        self.indtest_train_g = indtest_train_g.to(args.gpu)
        self.indtest_test_dataloader = DataLoader(indtest_test_dataset, batch_size=args.indtest_eval_bs,
                                                  shuffle=False, collate_fn=KGEEvalDataset.collate_fn)

        # models
        self.ent_init = EntInit(args).to(args.gpu)
        self.GatedFusion = GatedFusion(args).to(args.gpu)
        self.multiviewRGCN = MultiViewRGCN(args.num_nodes,args.in_dim,args.h_dim,args.out_dim,args.rel_nums,args).to(args.gpu)
        self.rgcn = RGCN(args).to(args.gpu)
        self.kge_model = KGEModel(args).to(args.gpu)

    def save_checkpoint(self, step):
        # ä¿å­˜éœ€è¦çš„å‚æ•°
        state = {'ent_init': self.ent_init.state_dict(),
                 'rgcn': self.rgcn.state_dict(),
                 'kge_model': self.kge_model.state_dict(),
                 'GatedFusion':self.GatedFusion.state_dict(),
                 'multiviewRGCN':self.multiviewRGCN.state_dict()
                 }
        # delete previous checkpoint
        for filename in os.listdir(self.state_path):
            if self.name in filename.split('.') and os.path.isfile(os.path.join(self.state_path, filename)):
                os.remove(os.path.join(self.state_path, filename))
        # save checkpoint
        torch.save(state, os.path.join(self.args.state_dir, self.name,
                                       self.name + '.' + str(step) + '.ckpt'))

    def save_model(self, best_step):
        os.rename(os.path.join(self.state_path, self.name + '.' + str(best_step) + '.ckpt'),
                  os.path.join(self.state_path, self.name + '.best'))

    def write_training_loss(self, loss, step):
        self.writer.add_scalar("training/loss", loss, step)

    def write_evaluation_result(self, results, step):
        """
        Write evaluation results (overall, event_query, entity_query) to TensorBoard.
        """
        for group_name, metrics in results.items():  # group_name: 'overall', 'event_query', etc.
            for metric_name, value in metrics.items():  # metric_name: 'mrr', 'hits@10', etc.
                tag = f"evaluation/{group_name}/{metric_name}"
                self.writer.add_scalar(tag, value, step)


    def before_test_load(self):
        state = torch.load(os.path.join(self.state_path, self.name + '.best'), map_location=self.args.gpu)
        self.ent_init.load_state_dict(state['ent_init'])
        self.rgcn.load_state_dict(state['rgcn'])
        self.kge_model.load_state_dict(state['kge_model'])
        self.GatedFusion.load_state_dict(state['GatedFusion'])
        # self.multiviewRGCN.load_state_dict(state['multiviewRGCN'])#?

    def check_dim_consistency(self,ent_emb, rel_emb, model_name=""):
        """
        æ£€æŸ¥å®ä½“/å…³ç³»åµŒå…¥æ˜¯å¦ç»´åº¦ä¸€è‡´ï¼Œé€‚ç”¨äº ComplExã€RotatE ç­‰æ¨¡å‹ã€‚

        å‚æ•°:
            ent_emb: å®ä½“åµŒå…¥ Tensor [N, d]
            rel_emb: å…³ç³»åµŒå…¥ Tensor [R, d]
            model_name: æ¨¡å‹åç§°ï¼Œç”¨äºæ¨¡å‹ç‰¹å®šé™åˆ¶

        æŠ›å‡º:
            ValueErrorï¼šå¦‚æœç»´åº¦ä¸ä¸€è‡´ï¼Œæˆ–ä¸æ»¡è¶³æ¨¡å‹è¦æ±‚
        """
        if ent_emb is None or rel_emb is None:
            raise ValueError("å®ä½“æˆ–å…³ç³»åµŒå…¥ä¸º None")

        if ent_emb.size(-1) != rel_emb.size(-1):
            raise ValueError(f" ç»´åº¦ä¸ä¸€è‡´ï¼šent_emb={ent_emb.size(-1)}, rel_emb={rel_emb.size(-1)}")

        if model_name in ['ComplEx', 'RotatE'] and ent_emb.size(-1) % 2 != 0:
            raise ValueError(f" {model_name} è¦æ±‚ embedding dim æ˜¯å¶æ•°ï¼Œå½“å‰ä¸º {ent_emb.size(-1)}")


    def get_loss(self, tri, neg_tail_ent, neg_head_ent, ent_emb, rel_emb,
                 explain_K=20, select_m=3,  # å€™é€‰è·¯å¾„æ•°é‡ & é€‰æ‹©æ•°é‡
                 tnorm="product",
                 lambda_abd=1.0, lambda_cons=0.5, lambda_len=0.01, margin=0.2,
                 temp=1.0):
        """
        åœ¨åŸ KGE æŸå¤±ä¸Šï¼Œè”åˆæº¯å› è§£é‡Šçš„ä¸‰é¡¹æŸå¤±ï¼š
          - L_abd: è§£é‡Šæ’åº/é€‰æ‹©ï¼ˆå¥½è·¯å¾„>åè·¯å¾„ï¼‰
          - L_cons: è§£é‡Šâ†’é¢„æµ‹ä¸€è‡´æ€§
          - L_len: ç®€æ´æ€§ï¼ˆæƒ©ç½šè¿‡é•¿è·¯å¾„ï¼‰
        å…¶ä½™å‚æ•°ä¸ä½ ç°æœ‰è®­ç»ƒä¿æŒå…¼å®¹ã€‚
        """

        # -----------------------------
        # 0) åŸæœ‰ KGE æŸå¤±ï¼ˆä¿ç•™ä¸åŠ¨ï¼‰
        # -----------------------------
        if neg_tail_ent is None:
            raise ValueError("tail_part is None! Check data loader or negative sampling.")

        self.check_dim_consistency(ent_emb, rel_emb, model_name=self.args.kge)

        neg_tail_score = self.kge_model((tri, neg_tail_ent), ent_emb, rel_emb, mode='tail-batch')
        neg_head_score = self.kge_model((tri, neg_head_ent), ent_emb, rel_emb, mode='head-batch')
        neg_score = torch.cat([neg_tail_score, neg_head_score], dim=0)
        neg_score = F.softmax(neg_score * self.args.adv_temp, dim=1).detach() * F.logsigmoid(-neg_score)

        pos_score_raw = self.kge_model(tri, ent_emb, rel_emb)  # æœªè¿‡sigmoidçš„åŸå§‹æ‰“åˆ†
        pos_score = F.logsigmoid(pos_score_raw).squeeze(dim=1)  # ç”¨äºåŸå§‹loss
        positive_sample_loss = - pos_score.mean()
        negative_sample_loss = - neg_score.mean()
        kge_loss = (positive_sample_loss + negative_sample_loss) / 2

        # -----------------------------
        # 1) ç”Ÿæˆå€™é€‰è§£é‡Šè·¯å¾„ï¼ˆADDï¼‰
        #    å‡å®šä½ æœ‰ self.explainer.generate(tri, K) -> list[list[Path]]
        #    æ¯æ¡ Path å«è‹¥å¹² Edgeï¼Œæ¯ä¸ª Edge å¸¦ mu_rel/mu_time/mu_attr ä¸ length=1
        # -----------------------------
        # paths_batch: é•¿åº¦ = batch_sizeï¼Œæ¯ä¸ªå…ƒç´ æ˜¯è¯¥æ ·æœ¬çš„å€™é€‰è·¯å¾„åˆ—è¡¨ï¼ˆé•¿åº¦<=explain_Kï¼‰
        paths_batch = self.explainer.generate(tri, K=explain_K)  # ä½ æ¥æä¾› explainerï¼ˆè§ä¸‹æ–‡â€œä½ éœ€è¦æä¾›çš„ä»£ç â€ï¼‰

        # -----------------------------
        # 2) è·¯å¾„æ‰“åˆ† + Gumbel/soft é€‰æ‹©ï¼ˆADDï¼‰
        #    S(P)= t-norm(mu_rel,mu_time,mu_attr) èšåˆ - é•¿åº¦æƒ©ç½š
        # -----------------------------
        def tnorm_agg(vals, kind="product"):
            if kind == "min":
                return torch.min(vals)
            elif kind == "lukasiewicz":
                # é€ä¸ªæŠ˜å  aâŠ—_L b = max(0, a + b - 1)
                s = vals[0]
                for v in vals[1:]:
                    s = torch.clamp(s + v - 1.0, min=0.0, max=1.0)
                return s
            else:  # product
                return torch.prod(vals)

        # per-sampleç»“æœå®¹å™¨
        S_list = []  # æ¯ä¸ªæ ·æœ¬å€™é€‰è·¯å¾„çš„åˆ†æ•° [num_paths]
        L_list = []  # å¯¹åº”è·¯å¾„é•¿åº¦
        Pi_list = []  # softé€‰æ‹©æƒé‡ [num_paths]ï¼ˆtop-m è¿‘ä¼¼ï¼‰
        top_paths_list = []  # å¯é€‰ï¼šå­˜æ”¾è¢«é€‰æ‹©çš„å‰mæ¡è·¯å¾„ç´¢å¼•

        # é’ˆå¯¹æ¯ä¸ªæ ·æœ¬
        for sample_paths in paths_batch:
            if len(sample_paths) == 0:
                S_list.append(torch.zeros(1, device=pos_score_raw.device))
                L_list.append(torch.ones(1, device=pos_score_raw.device))
                Pi_list.append(torch.ones(1, device=pos_score_raw.device))  # æ²¡æœ‰è§£é‡Šæ—¶ç»™ä¸ªæ’ç­‰
                top_paths_list.append([])
                continue

            scores = []
            lens = []
            for P in sample_paths:
                # æŠŠæ¯æ¡è·¯å¾„çš„å„ç±»å‹æ¨¡ç³Šåº¦åšèšåˆ
                mu_rel = torch.tensor([e.mu_rel for e in P.edges], device=pos_score_raw.device).clamp(0, 1)
                mu_time = torch.tensor([e.mu_time for e in P.edges], device=pos_score_raw.device).clamp(0, 1)
                mu_attr = torch.tensor([e.mu_attr for e in P.edges], device=pos_score_raw.device).clamp(0, 1)

                rel = tnorm_agg(mu_rel, tnorm)
                tim = tnorm_agg(mu_time, tnorm)
                att = tnorm_agg(mu_attr, tnorm)
                mix = tnorm_agg(torch.stack([rel, tim, att]), tnorm)

                # è·¯å¾„é•¿åº¦
                Lp = torch.tensor(len(P.edges), dtype=torch.float32, device=pos_score_raw.device)

                # è·¯å¾„æ€»åˆ†ï¼šmix - Î»_len * length   ï¼ˆæ’åºæ—¶ä¸åŠ  Î»_lenï¼Œè®­ç»ƒæ—¶ä¼šç”¨ L_len ç»Ÿä¸€æƒ©ç½šä¹Ÿå¯ï¼‰
                S_p = mix
                scores.append(S_p)
                lens.append(Lp)

            scores = torch.stack(scores)  # [num_paths]
            lens = torch.stack(lens)  # [num_paths]

            # soft/top-m é€‰æ‹©ï¼šç”¨softmaxæ¸©åº¦åšè¿‘ä¼¼ï¼ˆå¦‚éœ€ä¸¥æ ¼TopKï¼Œå¯ç”¨Gumbel-TopKï¼‰
            pi = torch.softmax(scores / max(1e-6, temp), dim=0)

            S_list.append(scores)
            L_list.append(lens)
            Pi_list.append(pi)

            # å¯é€‰ï¼šè®°å½•top-mç´¢å¼•ç”¨äºå¯è§†åŒ–
            if select_m > 0:
                top_idx = torch.topk(scores, k=min(select_m, scores.numel())).indices.tolist()
                top_paths_list.append(top_idx)
            else:
                top_paths_list.append([])

        # -----------------------------
        # 3) L_abdï¼šè§£é‡Šæ’åº/é€‰æ‹©ï¼ˆADDï¼‰
        #    æ­£è·¯å¾„ï¼šå€™é€‰ä¸­åˆ†æ•°é«˜ & æ—¶é—´/å…³ç³»ä¸€è‡´ï¼›è´Ÿè·¯å¾„ï¼šæ‰°åŠ¨ï¼ˆåå‘æ—¶é—´/æ¢å…³ç³»/æ–­è¾¹ï¼‰
        #    è¿™é‡Œç»™ä¸€ä¸ªç®€åŒ–çš„ margin ranking å®ç°ï¼šæ­£=softé€‰æ‹©çš„æœŸæœ›ï¼Œè´Ÿ=ä»è‡ªé€ è´Ÿè·¯å¾„é‡‡æ ·
        # -----------------------------
        # éœ€è¦ explainer æä¾›è´Ÿè·¯å¾„ç”Ÿæˆï¼ˆæˆ–åœ¨ explainer å†…éƒ¨åšï¼‰ï¼Œè¿™é‡ŒæŒ‰æ¥å£è°ƒç”¨
        neg_paths_batch = self.explainer.corrupt(paths_batch)  # ä¸ paths_batch ç»“æ„ä¸€è‡´çš„è´Ÿå€™é€‰

        def batch_paths_score(paths_batch):
            """å’Œä¸Šé¢ä¸€æ ·çš„æ‰“åˆ†ï¼Œå°æˆå‡½æ•°ç”¨äºè´Ÿæ ·æœ¬"""
            #è¿™é‡Œåº”è¯¥å°±æ˜¯ä¸‰ç±»æ¨¡ç³Šåº¦å…œåº•å§ï¼Œæ²¡æœ‰åšåŒºåˆ†
            out = []
            for sample_paths in paths_batch:
                if len(sample_paths) == 0:
                    out.append(torch.zeros(1, device=pos_score_raw.device))
                    continue
                s = []
                for P in sample_paths:
                    mu_rel = torch.tensor([e.mu_rel for e in P.edges], device=pos_score_raw.device).clamp(0, 1)
                    mu_time = torch.tensor([e.mu_time for e in P.edges], device=pos_score_raw.device).clamp(0, 1)
                    mu_attr = torch.tensor([e.mu_attr for e in P.edges], device=pos_score_raw.device).clamp(0, 1)
                    rel = tnorm_agg(mu_rel, tnorm)
                    tim = tnorm_agg(mu_time, tnorm)
                    att = tnorm_agg(mu_attr, tnorm)
                    mix = tnorm_agg(torch.stack([rel, tim, att]), tnorm)
                    s.append(mix)
                out.append(torch.stack(s))
            return out

        pos_paths_scores = S_list
        neg_paths_scores = batch_paths_score(neg_paths_batch)

        # å°†æ¯ä¸ªæ ·æœ¬çš„è§£é‡Šåˆ†åšâ€œsofté€‰æ‹©çš„æœŸæœ›â€
        pos_expect = []
        neg_expect = []
        for pos_s, pi, neg_s in zip(pos_paths_scores, Pi_list, neg_paths_scores):
            pos_expect.append((pi * pos_s).sum())
            # è´Ÿæ ·æœ¬ï¼šå–æœ€å¤§æˆ–å¹³å‡ï¼Œè¿™é‡Œå–æœ€å¤§ï¼ˆæ›´å¼ºå¯¹æ¯”ï¼‰
            if neg_s.numel() > 0:
                neg_expect.append(torch.max(neg_s))
            else:
                neg_expect.append(torch.tensor(0.0, device=pos_score_raw.device))
        pos_expect = torch.stack(pos_expect)  # [batch]
        neg_expect = torch.stack(neg_expect)  # [batch]

        L_abd = torch.clamp(margin - (pos_expect - neg_expect), min=0.0).mean()

        # -----------------------------
        # 4) L_consï¼šè§£é‡Šâ†’é¢„æµ‹ä¸€è‡´æ€§ï¼ˆADDï¼‰
        #    è®©è§£é‡Šå¼ºåº¦ï¼ˆæœŸæœ›åˆ†ï¼‰ä¸ä¸»é¢„æµ‹æ¦‚ç‡ä¸€è‡´ï¼šReLU(S_bar - y_hat)
        # -----------------------------
        y_hat = torch.sigmoid(pos_score_raw).squeeze(dim=1)  # [batch]
        S_bar = pos_expect.clamp(0, 1)  # [batch]
        L_cons = torch.relu(S_bar - y_hat).mean()

        # -----------------------------
        # 5) L_lenï¼šç®€æ´æ€§æ­£åˆ™ï¼ˆADDï¼‰
        #    ç”¨è¢«softé€‰æ‹©çš„æƒé‡å¯¹é•¿åº¦æ±‚æœŸæœ›ï¼Œå†åšå¹³å‡
        # -----------------------------
        len_expect = []
        for lens, pi in zip(L_list, Pi_list):
            len_expect.append((pi * lens).sum())
        len_expect = torch.stack(len_expect)
        L_len = len_expect.mean()

        # -----------------------------
        # 6) æ€»æŸå¤±
        # -----------------------------
        loss = kge_loss + lambda_abd * L_abd + lambda_cons * L_cons + lambda_len * L_len
        return loss

    def get_loss_1(self, tri, neg_tail_ent, neg_head_ent, ent_emb, rel_emb):
        """
        è®¡ç®— KGE æŸå¤±ï¼ŒåŒæ—¶åˆ©ç”¨å¢å¼ºåçš„ `rel_emb`

        å‚æ•°ï¼š
        - tri: çœŸå®ä¸‰å…ƒç»„ (h, r, t)
        - neg_tail_ent: è´Ÿæ ·æœ¬ (h, r, t')
        - neg_head_ent: è´Ÿæ ·æœ¬ (h', r, t)
        - ent_emb: å¢å¼ºåçš„å®ä½“åµŒå…¥
        - rel_emb: é€šè¿‡ GNN è®¡ç®—çš„å¢å¼ºå…³ç³»åµŒå…¥

        è¿”å›ï¼š
        - loss: KGE è®­ç»ƒæŸå¤±
        """

        if neg_tail_ent is None:
            raise ValueError("tail_part is None! Check data loader or negative sampling.")

        # è®¡ç®—è´Ÿæ ·æœ¬å¾—åˆ†
        # tail-batchå‡ºé”™
        self.check_dim_consistency(ent_emb, rel_emb, model_name=self.args.kge)
        neg_tail_score = self.kge_model((tri, neg_tail_ent), ent_emb, rel_emb, mode='tail-batch')
        neg_head_score = self.kge_model((tri, neg_head_ent), ent_emb, rel_emb, mode='head-batch')

        neg_score = torch.cat([neg_tail_score, neg_head_score], dim=0)  # æ‹¼æ¥è´Ÿæ ·æœ¬
        # neg_score = (F.softmax(neg_score * self.args.adv_temp, dim=1).detach()
        #              * F.logsigmoid(-neg_score)).sum(dim=1)

        neg_score = F.softmax(neg_score * self.args.adv_temp, dim=1).detach() * F.logsigmoid(-neg_score)

        # è®¡ç®—æ­£æ ·æœ¬å¾—åˆ†
        pos_score = self.kge_model(tri, ent_emb, rel_emb)
        pos_score = F.logsigmoid(pos_score).squeeze(dim=1)

        # è®¡ç®—æŸå¤±
        positive_sample_loss = - pos_score.mean()
        negative_sample_loss = - neg_score.mean()
        loss = (positive_sample_loss + negative_sample_loss) / 2

        return loss

    def get_ent_emb(self, sup_g_bidir):
        self.ent_init(sup_g_bidir)
        sup_g_bidir.ndata['h'] = sup_g_bidir.ndata['feat']
        ent_emb = self.rgcn(sup_g_bidir)

        return ent_emb

    def is_event3(self, global_id):
        return global_id >= len(self.args.test_entity2id)  # å¦‚æœtestæ–‡ä»¶å¤¹çš„åç§»åŒºåˆ†

    def is_event2(self, global_id):
        return global_id >= len(self.args.entity2id)  # å¦‚æœç”¨åç§»åŒºåˆ†

    def evaluate(self, ent_emb, rel_emb, eval_dataloader, local2global=None, num_cand='all'):
        results = ddict(float)
        event_results = ddict(float)
        entity_results = ddict(float)
        count = 0
        event_count = 0
        entity_count = 0

        eval_dataloader.dataset.num_cand = num_cand

        if num_cand == 'all':
            for batch in eval_dataloader:
                pos_triple, tail_label, head_label = [b.to(self.args.gpu) for b in batch]
                head_idx, rel_idx, tail_idx = pos_triple[:, 0], pos_triple[:, 1], pos_triple[:, 2]

                if rel_emb is None:
                    relation_triplets = self.generate_relation_triplets(
                        pos_triple.cpu().numpy(),
                        self.args.num_ent,
                        self.args.num_rel,
                        self.args.B
                    )
                    relation_triplets = torch.tensor(relation_triplets).to(self.args.gpu)
                    rel_emb = self.get_relation_emb(relation_triplets)

                b_range = torch.arange(pos_triple.size(0), device=self.args.gpu)

                # ----- tail prediction -----
                pred = self.kge_model((pos_triple, None), ent_emb, rel_emb, mode='tail-batch')
                target_pred = pred[b_range, tail_idx]
                pred = torch.where(tail_label.bool(), -torch.ones_like(pred) * 1e7, pred)
                pred[b_range, tail_idx] = target_pred
                tail_ranks = 1 + torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[
                    b_range, tail_idx]

                # ----- head prediction -----
                pred = self.kge_model((pos_triple, None), ent_emb, rel_emb, mode='head-batch')
                target_pred = pred[b_range, head_idx]
                pred = torch.where(head_label.bool(), -torch.ones_like(pred) * 1e7, pred)
                pred[b_range, head_idx] = target_pred
                head_ranks = 1 + torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[
                    b_range, head_idx]

                # ----- åˆ†å¼€ç»Ÿè®¡ -----
                for i in range(pos_triple.size(0)):
                    # tail è¯„ä¼°
                    tail_local_id = tail_idx[i].item()
                    tail_global_id = local2global[tail_local_id] if local2global else tail_local_id
                    is_event = self.is_event2(tail_global_id)

                    rank = tail_ranks[i].item()
                    count += 1
                    results['mr'] += rank
                    results['mrr'] += 1.0 / (rank + 1e-8)
                    for k in [1, 5, 10]:
                        if rank <= k:
                            results[f'hits@{k}'] += 1

                    if is_event:
                        event_count += 1
                        event_results['mr'] += rank
                        event_results['mrr'] += 1.0 / (rank + 1e-8)
                        for k in [1, 5, 10]:
                            if rank <= k:
                                event_results[f'hits@{k}'] += 1
                    else:
                        entity_count += 1
                        entity_results['mr'] += rank
                        entity_results['mrr'] += 1.0 / (rank + 1e-8)
                        for k in [1, 5, 10]:
                            if rank <= k:
                                entity_results[f'hits@{k}'] += 1

                    # head è¯„ä¼°
                    head_local_id = head_idx[i].item()
                    head_global_id = local2global[head_local_id] if local2global else head_local_id
                    is_event = self.is_event2(head_global_id)

                    rank = head_ranks[i].item()
                    count += 1
                    results['mr'] += rank
                    results['mrr'] += 1.0 / (rank + 1e-8)
                    for k in [1, 5, 10]:
                        if rank <= k:
                            results[f'hits@{k}'] += 1

                    if is_event:
                        event_count += 1
                        event_results['mr'] += rank
                        event_results['mrr'] += 1.0 / (rank + 1e-8)
                        for k in [1, 5, 10]:
                            if rank <= k:
                                event_results[f'hits@{k}'] += 1
                    else:
                        entity_count += 1
                        entity_results['mr'] += rank
                        entity_results['mrr'] += 1.0 / (rank + 1e-8)
                        for k in [1, 5, 10]:
                            if rank <= k:
                                entity_results[f'hits@{k}'] += 1


        else:
            for _ in range(self.args.num_sample_cand):
                for batch in eval_dataloader:
                    pos_triple, tail_cand, head_cand = [b.to(self.args.gpu) for b in batch]
                    b_range = torch.arange(pos_triple.size(0), device=self.args.gpu)
                    target_idx = torch.zeros(pos_triple.size(0), dtype=torch.long, device=self.args.gpu)

                    if rel_emb is None:
                        relation_triplets = self.generate_relation_triplets(
                            pos_triple.cpu().numpy(),
                            self.args.num_ent,
                            self.args.num_rel,
                            self.args.B
                        )
                        relation_triplets = torch.tensor(relation_triplets).to(self.args.gpu)
                        rel_emb = self.get_relation_emb(relation_triplets)

                    # ---- tail-batch ----
                    pred = self.kge_model((pos_triple, tail_cand), ent_emb, rel_emb, mode='tail-batch')
                    tail_ranks = 1 + \
                                 torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[
                                     b_range, target_idx]

                    # ---- head-batch ----
                    pred = self.kge_model((pos_triple, head_cand), ent_emb, rel_emb, mode='head-batch')
                    head_ranks = 1 + \
                                 torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[
                                     b_range, target_idx]

                    # ---- ç»Ÿè®¡ ----
                    for i in range(pos_triple.size(0)):
                        for role, idx, rank in [('tail', pos_triple[i][2], tail_ranks[i]),
                                                ('head', pos_triple[i][0], head_ranks[i])]:
                            local_id = idx.item()
                            global_id = local2global[local_id] if local2global else local_id
                            is_event = self.is_event3(global_id)

                            rank = rank.item()
                            count += 1
                            results['mr'] += rank
                            results['mrr'] += 1.0 / (rank + 1e-8)
                            for k in [1, 5, 10]:
                                if rank <= k:
                                    results[f'hits@{k}'] += 1

                            if is_event:
                                event_count += 1
                                event_results['mr'] += rank
                                event_results['mrr'] += 1.0 / (rank + 1e-8)
                                for k in [1, 5, 10]:
                                    if rank <= k:
                                        event_results[f'hits@{k}'] += 1
                            else:
                                entity_count += 1
                                entity_results['mr'] += rank
                                entity_results['mrr'] += 1.0 / (rank + 1e-8)
                                for k in [1, 5, 10]:
                                    if rank <= k:
                                        entity_results[f'hits@{k}'] += 1

        # ---- ç»“æœå½’ä¸€åŒ– ----
        for k in results:
            results[k] /= count
        for k in event_results:
            event_results[k] /= event_count
        for k in entity_results:
            entity_results[k] /= entity_count



        return {
            "overall": results,
            "event_query": event_results,
            "entity_query": entity_results
        }

    def load_multiview_model_for_inductive(self,test_model, checkpoint_path, device='cuda:0'):
        """
        ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­åŠ è½½ MultiViewRGCN çš„å¯è¿ç§»å‚æ•°åˆ°æµ‹è¯•å›¾æ¨¡å‹ä¸­ï¼ˆå½’çº³è®¾ç½®ï¼‰ã€‚

        å‚æ•°:
            test_model: æ„å»ºå¥½çš„ MultiViewRGCNï¼ˆé’ˆå¯¹æµ‹è¯•å›¾ç»“æ„åˆå§‹åŒ–ï¼‰
            checkpoint_path: è®­ç»ƒé˜¶æ®µä¿å­˜çš„æ¨¡å‹è·¯å¾„
            device: åŠ è½½æ¨¡å‹åˆ°å“ªä¸ªè®¾å¤‡
        """
        import torch

        # åŠ è½½ checkpoint
        print(f"ğŸ” Loading pretrained MultiViewRGCN from: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device)

        if 'multiviewRGCN' not in checkpoint:
            raise KeyError("Checkpoint does not contain 'multiviewRGCN'!")

        pretrained_state = checkpoint['multiviewRGCN']
        current_state = test_model.state_dict()

        # è¿‡æ»¤åŒ¹é…çš„å‚æ•°ï¼ˆè·³è¿‡å½¢çŠ¶ä¸åŒ¹é…çš„ï¼‰
        filtered = {
            k: v for k, v in pretrained_state.items()
            if k in current_state and current_state[k].shape == v.shape
        }

        # åŠ è½½
        missing_keys, unexpected_keys = test_model.load_state_dict(filtered, strict=False)

        print(f" Loaded {len(filtered)} matching parameters into test MultiViewRGCN.")
        if missing_keys:
            print(f" Missing keys: {missing_keys}")
        if unexpected_keys:
            print(f"  Unexpected keys: {unexpected_keys}")

        return test_model

    def get_test_embedd(self):
        import torch.nn as nn

        test_num_nodes = len(self.args.test_entity2id) + len(self.args.test_event2id)

        # æ¯æ¬¡éƒ½æ„å»ºå›¾ï¼Œä½†æ‰‹åŠ¨é‡Šæ”¾
        test_g1 = self.build_dgl_graph(self.args.test_ee_edges, self.args).to(self.args.gpu)
        test_g2 = self.build_dgl_graph(self.args.test_ev_edges, self.args).to(self.args.gpu)
        test_g3 = self.build_dgl_graph(self.args.test_vv_edges, self.args).to(self.args.gpu)

        #  æ¨¡å‹åªæ„å»ºä¸€æ¬¡ï¼Œåç»­å¤ç”¨ï¼ˆåœ¨ç±»ä¸­å…ˆå®šä¹‰ self.test_model = Noneï¼‰
        if self.test_model is None:
            self.test_model = MultiViewRGCN(
                num_nodes=test_num_nodes,
                in_dim=self.args.in_dim,
                h_dim=self.args.h_dim,
                out_dim=self.args.out_dim,
                rel_nums=self.args.test_rel_nums,args=self.args).to(self.args.gpu)

            #  åŠ è½½å‚æ•°ï¼Œåªåšä¸€æ¬¡
            self.load_multiview_model_for_inductive(
                self.test_model,
                checkpoint_path=os.path.join(self.state_path, self.name + '.best'),
                device=self.args.gpu
            )

        # æ¯æ¬¡åªæ›´æ–°èŠ‚ç‚¹åµŒå…¥ï¼ˆå…±äº«æ¨¡å‹ï¼‰
        self.test_model.node_features = nn.Parameter(
            torch.randn(test_num_nodes, self.args.in_dim).to(self.args.gpu)
        )

        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            test_emb = self.test_model(
                graphs=[test_g1, test_g2, test_g3],
                rel_types=[
                    test_g1.edata['rel_type'],
                    test_g2.edata['rel_type'],
                    test_g3.edata['rel_type']
                ]
            ).detach()

        # å¼ºåˆ¶é‡Šæ”¾å›¾æ˜¾å­˜ï¼ˆé¿å…æ®‹ç•™ï¼‰
        del test_g1, test_g2, test_g3
        del self.test_model.node_features
        torch.cuda.empty_cache()

        return test_emb

    def evaluate_indtest_test_triples(self, num_cand='all'):
        """do evaluation on test triples of ind-test-graph"""
        ent_emb = self.get_ent_emb(self.indtest_train_g)  # indtestçš„dglåŒå‘å›¾
        test_emb = self.get_test_embedd()

        ent_emb_fused = self.GatedFusion(ent_emb, test_emb)

        results = self.evaluate(ent_emb_fused, None, self.indtest_test_dataloader,  num_cand=num_cand)

        self.logger.info(f'test on ind-test-graph, sample {num_cand}')
        # è¾“å‡º Overall ç»“æœ
        overall = results['overall']
        self.logger.info("[Overall]     MRR: {:.4f}, Hits@1: {:.4f}, Hits@5: {:.4f}, Hits@10: {:.4f}".format(
            overall['mrr'], overall['hits@1'], overall['hits@5'], overall['hits@10']
        ))

        # è¾“å‡º Event Query ç»“æœ
        event = results['event_query']
        self.logger.info("[Event Query] MRR: {:.4f}, Hits@1: {:.4f}, Hits@5: {:.4f}, Hits@10: {:.4f}".format(
            event['mrr'], event['hits@1'], event['hits@5'], event['hits@10']
        ))

        # è¾“å‡º Entity Query ç»“æœ
        entity = results['entity_query']
        self.logger.info("[Entity Query]MRR: {:.4f}, Hits@1: {:.4f}, Hits@5: {:.4f}, Hits@10: {:.4f}".format(
            entity['mrr'], entity['hits@1'], entity['hits@5'], entity['hits@10']
        ))


        del self.test_model
        self.test_model = None
        torch.cuda.empty_cache()

        return results
